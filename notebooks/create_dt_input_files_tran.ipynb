{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creation of input files for the DT\n",
    "### Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from math import log\n",
    "\n",
    "basepath = \"/mnt/container-nle-neoagdt/data/tran2015/\"\n",
    "\n",
    "variants_out = \"variants.csv\"\n",
    "peptide_sequences_out = \"peptide-sequences.csv\"\n",
    "genes_out = \"genes.csv\"\n",
    "hlas_out = \"hlas.csv\"\n",
    "binding_scores_out = \"binding-scores.csv\"\n",
    "\n",
    "# Generate gene mapping dict\n",
    "genemap = dict()\n",
    "with open(os.path.join(basepath.replace('tran2015', ''), 'genenames_mapping.txt'), 'r') as fh:\n",
    "    for row in fh:\n",
    "        columns = row.split('\\t')\n",
    "        genemap[columns[1].upper()] = columns[10] # alternatively column 12\n",
    "        genemap[columns[10].upper()] = columns[10]\n",
    "        for i in [4, 5, 7]:\n",
    "            if columns[i] is not None:\n",
    "                csplit = columns[i].split(',')\n",
    "                for altname in csplit:\n",
    "                        genemap[altname.strip().upper()] = columns[10]\n",
    "samples = [x for x in os.listdir(basepath) if x.isnumeric()]\n",
    "# Excluding sample 3971 since it is not present in the supplementary mutation tables\n",
    "samples.remove('3971')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_expression(sample):\n",
    "    return pd.read_csv(os.path.join(basepath, sample, 'rna', 'genes.fpkm_tracking'), sep='\\t')\n",
    "\n",
    "def load_prediction(sample):\n",
    "    return pd.read_csv(os.path.join(basepath, sample, 'MHC_Class_I', \n",
    "                                    '{}.all_epitopes.netchop.tsv'.format(sample)), sep='\\t')\n",
    "\n",
    "def load_stability(sample):\n",
    "    return pd.read_csv(os.path.join(basepath, sample, 'MHC_Class_I', \n",
    "                                    '{}.all_epitopes.netmhcstab.tsv'.format(sample)), sep='\\t')\n",
    "\n",
    "def load_mutation(sample):\n",
    "    df = pd.read_excel(os.path.join(basepath.replace('tran2015', 'tran2015_supp'), \n",
    "                                      'tran_patients_mutations.xlsx'), sheet_name=sample, skiprows=3, header=None)\n",
    "    # Accounting for mistake of swapping wt and mut in sample 3812\n",
    "    if sample == '3812':\n",
    "       df[4] = df[4].apply(\n",
    "           lambda x: ''.join([x[0:-3], x[-3:len(x)].split('>')[1], '>', x[-3:len(x)].split('>')[0]]) \n",
    "           if not pd.isnull(x) else np.NaN\n",
    "       )\n",
    "    return df\n",
    "\n",
    "def load_hla(sample):\n",
    "    return pd.read_csv(os.path.join(basepath, sample, 'hlatyping.txt'), sep=',', header=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "#### Predictions and peptide sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    # Load data\n",
    "    df_stab = load_stability(sample)\n",
    "    df_pred = load_prediction(sample)\n",
    "    df_pred = pd.merge(df_pred, df_stab,  \n",
    "                       how='left', \n",
    "                       left_on=['Mutation','Epitope Seq', 'HLA Allele'], \n",
    "                       right_on = ['Mutation','Epitope Seq', 'HLA Allele'])   \n",
    "    \n",
    "    # Scores and column mapping\n",
    "    df_pred['allele name'] = df_pred['HLA Allele'].apply(\n",
    "        lambda x: x.split('-')[1].translate({ord(i): None for i in '*:'}))\n",
    "    df_pred['genename'] = df_pred['Mutation'].apply(lambda x: x.split('_')[0])\n",
    "    df_pred['gene_id'] = df_pred['genename'].apply(\n",
    "        lambda x: genemap[x.upper()] if x.upper() in genemap.keys() else np.NaN)\n",
    "    df_pred['Mutation_ID'] = df_pred['Mutation'].apply(\n",
    "        lambda x: '_'.join([str(genemap[x.split('_')[0].upper()]),\n",
    "                            ''.join([i for i in x.split('_')[1] if not i.isdigit()])]) \n",
    "        if x.split('_')[0].upper() in genemap.keys() else np.NaN)\n",
    "    df_pred['Mut_peptide'] = df_pred['Epitope Seq']\n",
    "    df_pred['binding_score'] = df_pred['NetMHCpan Percentile_x'].apply(lambda x: 1 - x / 100)\n",
    "    df_pred['cleavage_score'] = df_pred['Best Cleavage Score']\n",
    "    df_pred['stability_score'] = df_pred['Predicted Stability']\n",
    "    \n",
    "    # Create list of all gene names that could not be mapped\n",
    "    f = open(os.path.join(basepath, sample, 'unmapped_genes.txt'), 'w')\n",
    "    for i in df_pred.loc[df_pred['gene_id'].isnull()]['genename'].unique():\n",
    "        f.write(i + '\\n')\n",
    "    f.close() \n",
    "    \n",
    "    # Filter for unmapped genes\n",
    "    df_pred = df_pred.dropna(subset = ['gene_id'])\n",
    "    \n",
    "    # Sample specific cleanup\n",
    "    if sample == '3812':\n",
    "        df_pred['Mutation_ID'] = df_pred['Mutation_ID'].apply(lambda x: x.replace('.', ''))\n",
    "    \n",
    "    # Export\n",
    "    df_pred.to_csv(os.path.join(basepath, sample, peptide_sequences_out),\n",
    "              index=False, \n",
    "              columns=['Mutation_ID', 'Mut_peptide'])\n",
    "    df_pred.to_csv(os.path.join(basepath, sample, binding_scores_out),\n",
    "              index=False, \n",
    "              columns=['allele name', 'gene_id', 'Mutation_ID', 'Mut_peptide', \n",
    "                       'binding_score', 'cleavage_score', 'stability_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    # Load data\n",
    "    df_expr = load_expression(sample)\n",
    "    df_expr['gene_id'] = df_expr['tracking_id'].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "    # Convert confidence interval to variance\n",
    "    Z = 3.92 # two-sided since we use (high-low)\n",
    "    std = (df_expr['FPKM_conf_hi'] - df_expr['FPKM_conf_lo']) / Z\n",
    "    var = np.power(std, 2)\n",
    "    df_expr['FPKM_VAR'] = var\n",
    "\n",
    "    # Export\n",
    "    df_expr.to_csv(os.path.join(basepath, sample, genes_out),\n",
    "              index=False, \n",
    "              columns=['tracking_id', 'gene_id', 'gene_short_name', 'FPKM', 'FPKM_VAR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HLA allele specific expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    # Load data\n",
    "    df_expr = load_expression(sample)\n",
    "    # Map typed HLA alleles to gene identfier\n",
    "    df_hla = df_expr[df_expr['gene_short_name'].str.startswith('HLA')]\n",
    "\n",
    "    allele_name = list()\n",
    "    gene_id = list()\n",
    "    for allele in load_hla(sample).loc[0].to_list():\n",
    "        allele_name.append(allele.split('-')[1].replace('*', '').replace(':', ''))\n",
    "        gene_id.append(\n",
    "            df_hla.loc[df_hla['gene_short_name'] == allele.split('*')[0], 'tracking_id'].iloc[0].split('.')[0])\n",
    "\n",
    "    # Export\n",
    "    pd.DataFrame(list(zip(allele_name, gene_id)),\n",
    "                 columns =['allele_name', 'gene_id']\n",
    "                ).to_csv(os.path.join(basepath, sample, hlas_out), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    # Load data\n",
    "    df_mut = load_mutation(sample)\n",
    "    df_pep = pd.read_csv(os.path.join(basepath, sample, peptide_sequences_out))\n",
    "    df_mut['Gene_ID'] = df_mut[0].apply(lambda x: genemap[x.split('.')[0].upper()] \n",
    "                                            if x.split('.')[0].upper() in genemap.keys() else np.NaN)\n",
    "    df_mut['Mutation_ID'] = df_mut.apply(\n",
    "        lambda dfrow: '_'.join([genemap[dfrow[0].split('.')[0].upper()] \n",
    "                                if dfrow[0].split('.')[0].upper().split('.')[0].upper() in genemap.keys() \n",
    "                                else str(np.NaN), str(dfrow[4])]), axis=1)\n",
    "    df_mut['Mutation_ID'] = df_mut['Mutation_ID'].apply(\n",
    "        lambda x: '_'.join([x.split('_')[0], ''.join([i for i in x.split('_')[1] if not i.isdigit()])])) \n",
    "    df_mut['VAF'] = df_mut[7]\n",
    "\n",
    "    df_mut = pd.merge(df_mut, df_pep,  \n",
    "                        how='left', on='Mutation_ID')\n",
    "    \n",
    "    # Export\n",
    "    df_mut.to_csv(os.path.join(basepath, sample, variants_out),\n",
    "                    index=False, \n",
    "                    columns=['Mutation_ID', 'Gene_ID', 'VAF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}